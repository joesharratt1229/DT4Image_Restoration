{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from dataset.datasets import EvaluationDataset\n",
    "from transformer.decision_transformer import DecisionTransformer, DecisionTransformerConfig\n",
    "from evaluation.env import PnPEnv\n",
    "from evaluation.noise import UNetDenoiser2D\n",
    "\n",
    "denoiser = UNetDenoiser2D(ckpt_path='evaluation/pretrained/unet-nm.pt')\n",
    "\n",
    "model_config = DecisionTransformerConfig(block_size = 18)\n",
    "\n",
    "\n",
    "model = DecisionTransformer(model_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoesharratt1229\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/MetaRLforPnP/wandb/run-20240302_145343-jhs9ksyi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joesharratt1229/decision_transformer/runs/jhs9ksyi' target=\"_blank\">confused-violet-94</a></strong> to <a href='https://wandb.ai/joesharratt1229/decision_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joesharratt1229/decision_transformer' target=\"_blank\">https://wandb.ai/joesharratt1229/decision_transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joesharratt1229/decision_transformer/runs/jhs9ksyi' target=\"_blank\">https://wandb.ai/joesharratt1229/decision_transformer/runs/jhs9ksyi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train import Trainer, TrainerConfig\n",
    "\n",
    "train_dict = {\n",
    "    'learning_rate' : 3e-4,\n",
    "    'beta' :(0.9, 0.95),\n",
    "    'weight_decay' : 0.1,\n",
    "    'grad_norm_clipping': 1.0,\n",
    "    'num_workers': 0,\n",
    "}\n",
    "\n",
    "train_dict['batch_size'] = 1\n",
    "train_dict['block_size'] = 18\n",
    "train_dict['max_epochs'] = None\n",
    "\n",
    "train_config = TrainerConfig(**train_dict)\n",
    "rtg_target = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "env = PnPEnv(max_episode_step=30, denoiser = denoiser, device_type=torch.device('cuda'))\n",
    "optimizer = model.configure_optimizers(train_config)\n",
    "vanilla_eval_dataset = EvaluationDataset(block_size = train_config.block_size//3, rtg_scale = 1, data_dir='evaluation/image_dir/vanilla/4_5/', action_dim= 3, rtg_target = rtg_target)\n",
    "eval_loader = DataLoader(dataset = vanilla_eval_dataset, batch_size=1) \n",
    "\n",
    "trainer = Trainer(model = model, train_config=train_config, action_dim=3, max_timesteps=30, context_length=6, train_data_loader=None, optimizer=optimizer, \n",
    "                  save_every=1, env = env, eval_loader= eval_loader, gpu_id= None, ddp = False, compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_5_3DMR_Chest.mat\n",
      "Original reward 24.085483204576434\n",
      "13\n",
      "Final reward {28.951027274119202}\n",
      "4_5_3DMR_Renal_Arteries.mat\n",
      "Original reward 25.77344854402682\n",
      "12\n",
      "Final reward {31.598738136524858}\n",
      "4_5_Brain.mat\n",
      "Original reward 20.66281719367378\n",
      "13\n",
      "Final reward {26.661656305778145}\n",
      "4_5_Brain_data1.mat\n",
      "Original reward 27.49327933419024\n",
      "13\n",
      "Final reward {34.34641922200724}\n",
      "4_5_Brain_data2.mat\n",
      "Original reward 25.99797477060088\n",
      "13\n",
      "Final reward {31.2306492197709}\n",
      "4_5_Bust.mat\n",
      "Original reward 24.08248633327879\n",
      "13\n",
      "Final reward {31.02807433194213}\n",
      "4_5_Heart.mat\n",
      "Original reward 28.65738746634284\n",
      "12\n",
      "Final reward {30.759717304831614}\n"
     ]
    }
   ],
   "source": [
    "trainer.run_evaluation(rtg_scale = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_5_3DMR_Chest.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original reward 21.767805594616064\n",
      "13\n",
      "Final reward {25.187120920999796}\n",
      "8_5_3DMR_Renal_Arteries.mat\n",
      "Original reward 23.018381977306102\n",
      "12\n",
      "Final reward {27.946174858007552}\n",
      "8_5_Brain.mat\n",
      "Original reward 18.257236630290144\n",
      "13\n",
      "Final reward {22.00072739422186}\n",
      "8_5_Brain_data1.mat\n",
      "Original reward 24.038445092261735\n",
      "13\n",
      "Final reward {31.261477991874887}\n",
      "8_5_Brain_data2.mat\n",
      "Original reward 22.68603955596646\n",
      "13\n",
      "Final reward {27.824051678674294}\n",
      "8_5_Bust.mat\n",
      "Original reward 21.2675938517437\n",
      "13\n",
      "Final reward {27.628554379213384}\n",
      "8_5_Heart.mat\n",
      "Original reward 25.297600698275502\n",
      "12\n",
      "Final reward {29.77429872503386}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "optimizer = model.configure_optimizers(train_config)\n",
    "vanilla_eval_dataset = EvaluationDataset(block_size = train_config.block_size//3, rtg_scale = 1, data_dir='evaluation/image_dir/vanilla/8_5/', action_dim= 3, rtg_target = rtg_target)\n",
    "eval_loader = DataLoader(dataset = vanilla_eval_dataset, batch_size=1) \n",
    "\n",
    "trainer = Trainer(model = model, train_config=train_config, action_dim=3, max_timesteps=30, context_length=6, train_data_loader=None, optimizer=optimizer, \n",
    "                  save_every=1, env = env, eval_loader= eval_loader, gpu_id= None, ddp = False, compile=False)\n",
    "\n",
    "trainer.run_evaluation(rtg_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_15_3DMR_Chest.mat\n",
      "Original reward 23.307081489543044\n",
      "13\n",
      "Final reward {25.888090085710186}\n",
      "4_15_3DMR_Renal_Arteries.mat\n",
      "Original reward 24.77569546543013\n",
      "12\n",
      "Final reward {27.216073946050997}\n",
      "4_15_Brain.mat\n",
      "Original reward 20.345594464474352\n",
      "13\n",
      "Final reward {24.016790077931528}\n",
      "4_15_Brain_data1.mat\n",
      "Original reward 26.160903944886257\n",
      "13\n",
      "Final reward {29.479708719113557}\n",
      "4_15_Brain_data2.mat\n",
      "Original reward 24.92526977802324\n",
      "13\n",
      "Final reward {27.849753384027544}\n",
      "4_15_Bust.mat\n",
      "Original reward 23.40915027079623\n",
      "13\n",
      "Final reward {26.766756275033995}\n",
      "4_15_Heart.mat\n",
      "Original reward 26.882332669385328\n",
      "12\n",
      "Final reward {27.962260200401264}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "optimizer = model.configure_optimizers(train_config)\n",
    "vanilla_eval_dataset = EvaluationDataset(block_size = train_config.block_size//3, rtg_scale = 1, data_dir='evaluation/image_dir/vanilla/4_15/', action_dim= 3, rtg_target = rtg_target)\n",
    "eval_loader = DataLoader(dataset = vanilla_eval_dataset, batch_size=1) \n",
    "\n",
    "trainer = Trainer(model = model, train_config=train_config, action_dim=3, max_timesteps=30, context_length=6, train_data_loader=None, optimizer=optimizer, \n",
    "                  save_every=1, env = env, eval_loader= eval_loader, gpu_id= None, ddp = False, compile=False)\n",
    "\n",
    "trainer.run_evaluation(rtg_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_15_3DMR_Chest.mat\n",
      "Original reward 21.518847991695992\n",
      "13\n",
      "Final reward {23.822214485598256}\n",
      "8_15_3DMR_Renal_Arteries.mat\n",
      "Original reward 22.736606930897544\n",
      "12\n",
      "Final reward {25.505295184259182}\n",
      "8_15_Brain.mat\n",
      "Original reward 18.14285856888662\n",
      "13\n",
      "Final reward {21.106447748994484}\n",
      "8_15_Brain_data1.mat\n",
      "Original reward 23.72405326112023\n",
      "13\n",
      "Final reward {29.295052704085297}\n",
      "8_15_Brain_data2.mat\n",
      "Original reward 22.378754873698394\n",
      "13\n",
      "Final reward {26.327529421093683}\n",
      "8_15_Bust.mat\n",
      "Original reward 21.091775343967317\n",
      "13\n",
      "Final reward {25.18197288478499}\n",
      "8_15_Heart.mat\n",
      "Original reward 24.81741888268676\n",
      "12\n",
      "Final reward {27.893274625612268}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "optimizer = model.configure_optimizers(train_config)\n",
    "#NEED DECIDE -> WHETHER 4 OR 7 (4 IS BETTER but still)\n",
    "vanilla_eval_dataset = EvaluationDataset(block_size = train_config.block_size//3, rtg_scale = 1, data_dir='evaluation/image_dir/vanilla/8_15/', action_dim= 3, rtg_target = rtg_target)\n",
    "eval_loader = DataLoader(dataset = vanilla_eval_dataset, batch_size=1) \n",
    "\n",
    "trainer = Trainer(model = model, train_config=train_config, action_dim=3, max_timesteps=30, context_length=6, train_data_loader=None, optimizer=optimizer, \n",
    "                  save_every=1, env = env, eval_loader= eval_loader, gpu_id= None, ddp = False, compile=False)\n",
    "\n",
    "trainer.run_evaluation(rtg_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5_3DMR_Chest.mat\n",
      "Original reward 27.894389975474603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Final reward {32.13198586445769}\n",
      "2_5_3DMR_Renal_Arteries.mat\n",
      "Original reward 29.25462338128174\n",
      "12\n",
      "Final reward {34.40845584513417}\n",
      "2_5_Brain.mat\n",
      "Original reward 24.714582167421923\n",
      "13\n",
      "Final reward {31.123245438176546}\n",
      "2_5_Brain_data1.mat\n",
      "Original reward 32.67983702397251\n",
      "13\n",
      "Final reward {36.832864975240426}\n",
      "2_5_Brain_data2.mat\n",
      "Original reward 30.547650982631044\n",
      "13\n",
      "Final reward {34.29079243809126}\n",
      "2_5_Bust.mat\n",
      "Original reward 28.386992395578208\n",
      "13\n",
      "Final reward {33.87201056885906}\n",
      "2_5_Heart.mat\n",
      "Original reward 32.75866757151102\n",
      "12\n",
      "Final reward {34.906280530959684}\n"
     ]
    }
   ],
   "source": [
    "vanilla_eval_dataset = EvaluationDataset(block_size = \n",
    "                                         train_config.block_size//3, \n",
    "                                         rtg_scale = 1, \n",
    "                                         data_dir='evaluation/image_dir/metalearning/2_5/', \n",
    "                                         action_dim= 3, \n",
    "                                         rtg_target = rtg_target)\n",
    "eval_loader = DataLoader(dataset = vanilla_eval_dataset, batch_size=1) \n",
    "\n",
    "trainer = Trainer(model = model, train_config=train_config, action_dim=3, max_timesteps=30, context_length=6, train_data_loader=None, optimizer=optimizer, \n",
    "                  save_every=1, env = env, eval_loader= eval_loader, gpu_id= None, ddp = False, compile=False)\n",
    "\n",
    "trainer.run_evaluation(rtg_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_10_3DMR_Chest.mat\n",
      "Original reward 26.687000416044064\n",
      "13\n",
      "Final reward {30.232463478606398}\n",
      "2_10_3DMR_Renal_Arteries.mat\n",
      "Original reward 27.776084406628662\n",
      "12\n",
      "Final reward {32.16186539165613}\n",
      "2_10_Brain.mat\n",
      "Original reward 24.141109438876658\n",
      "13\n",
      "Final reward {28.91716783118713}\n",
      "2_10_Brain_data1.mat\n",
      "Original reward 30.20655412935882\n",
      "13\n",
      "Final reward {33.77278338418738}\n",
      "2_10_Brain_data2.mat\n",
      "Original reward 28.643676893102636\n",
      "13\n",
      "Final reward {32.11883754298874}\n",
      "2_10_Bust.mat\n",
      "Original reward 27.243768049266453\n",
      "13\n",
      "Final reward {31.32967871120721}\n",
      "2_10_Heart.mat\n",
      "Original reward 30.011063705214312\n",
      "12\n",
      "Final reward {32.804475513878934}\n"
     ]
    }
   ],
   "source": [
    "vanilla_eval_dataset = EvaluationDataset(block_size = \n",
    "                                         train_config.block_size//3, \n",
    "                                         rtg_scale = 1, \n",
    "                                         data_dir='evaluation/image_dir/metalearning/2_10/', \n",
    "                                         action_dim= 3, \n",
    "                                         rtg_target = rtg_target)\n",
    "eval_loader = DataLoader(dataset = vanilla_eval_dataset, batch_size=1) \n",
    "\n",
    "trainer = Trainer(model = model, train_config=train_config, action_dim=3, max_timesteps=30, context_length=6, train_data_loader=None, optimizer=optimizer, \n",
    "                  save_every=1, env = env, eval_loader= eval_loader, gpu_id= None, ddp = False, compile=False)\n",
    "\n",
    "trainer.run_evaluation(rtg_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_15_3DMR_Chest.mat\n",
      "Original reward 25.230348235406407\n",
      "13\n",
      "Final reward {26.652525692747453}\n",
      "2_15_3DMR_Renal_Arteries.mat\n",
      "Original reward 26.197690490670293\n",
      "13\n",
      "Final reward {27.25660451643831}\n",
      "2_15_Brain.mat\n",
      "Original reward 23.347199158640887\n",
      "13\n",
      "Final reward {25.657997193739543}\n",
      "2_15_Brain_data1.mat\n",
      "Original reward 27.859013940325838\n",
      "13\n",
      "Final reward {28.025032604088103}\n",
      "2_15_Brain_data2.mat\n",
      "Original reward 26.605300400521436\n",
      "13\n",
      "Final reward {27.52558980152831}\n",
      "2_15_Bust.mat\n",
      "Original reward 25.915610031180137\n",
      "13\n",
      "Final reward {26.956845189961378}\n",
      "2_15_Heart.mat\n",
      "Original reward 27.665680383327178\n",
      "12\n",
      "Final reward {27.290655858529853}\n"
     ]
    }
   ],
   "source": [
    "vanilla_eval_dataset = EvaluationDataset(block_size = \n",
    "                                         train_config.block_size//3, \n",
    "                                         rtg_scale = 1, \n",
    "                                         data_dir='evaluation/image_dir/metalearning/2_15/', \n",
    "                                         action_dim= 3, \n",
    "                                         rtg_target = rtg_target)\n",
    "eval_loader = DataLoader(dataset = vanilla_eval_dataset, batch_size=1) \n",
    "\n",
    "trainer = Trainer(model = model, train_config=train_config, action_dim=3, max_timesteps=30, context_length=6, train_data_loader=None, optimizer=optimizer, \n",
    "                  save_every=1, env = env, eval_loader= eval_loader, gpu_id= None, ddp = False, compile=False)\n",
    "\n",
    "trainer.run_evaluation(rtg_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_10_3DMR_Chest.mat\n",
      "Original reward 23.75387844349072\n",
      "13\n",
      "Final reward {27.986004951992097}\n",
      "4_10_3DMR_Renal_Arteries.mat\n",
      "Original reward 25.37565318675795\n",
      "12\n",
      "Final reward {30.00319423395249}\n",
      "4_10_Brain.mat\n",
      "Original reward 20.525580127967793\n",
      "13\n",
      "Final reward {25.753091127273837}\n",
      "4_10_Brain_data1.mat\n",
      "Original reward 26.991789895128772\n",
      "13\n",
      "Final reward {33.80654303369291}\n",
      "4_10_Brain_data2.mat\n",
      "Original reward 25.570559951834404\n",
      "13\n",
      "Final reward {30.357316141035472}\n",
      "4_10_Bust.mat\n",
      "Original reward 23.835859478468468\n",
      "13\n",
      "Final reward {29.77377163715839}\n",
      "4_10_Heart.mat\n",
      "Original reward 27.91069192305431\n",
      "12\n",
      "Final reward {30.363563739889262}\n"
     ]
    }
   ],
   "source": [
    "vanilla_eval_dataset = EvaluationDataset(block_size = \n",
    "                                         train_config.block_size//3, \n",
    "                                         rtg_scale = 1, \n",
    "                                         data_dir='evaluation/image_dir/metalearning/4_10/', \n",
    "                                         action_dim= 3, \n",
    "                                         rtg_target = rtg_target)\n",
    "eval_loader = DataLoader(dataset = vanilla_eval_dataset, batch_size=1) \n",
    "\n",
    "trainer = Trainer(model = model, train_config=train_config, action_dim=3, max_timesteps=30, context_length=6, train_data_loader=None, optimizer=optimizer, \n",
    "                  save_every=1, env = env, eval_loader= eval_loader, gpu_id= None, ddp = False, compile=False)\n",
    "\n",
    "trainer.run_evaluation(rtg_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_10_3DMR_Chest.mat\n",
      "Original reward 21.662603163080046\n",
      "13\n",
      "Final reward {24.9391391379365}\n",
      "8_10_3DMR_Renal_Arteries.mat\n",
      "Original reward 22.908173032271947\n",
      "12\n",
      "Final reward {26.815842864849273}\n",
      "8_10_Brain.mat\n",
      "Original reward 18.222857971625217\n",
      "13\n",
      "Final reward {21.701579672457335}\n",
      "8_10_Brain_data1.mat\n",
      "Original reward 23.926840024928463\n",
      "13\n",
      "Final reward {31.05487091687965}\n",
      "8_10_Brain_data2.mat\n",
      "Original reward 22.56851873704616\n",
      "13\n",
      "Final reward {27.46392071818079}\n",
      "8_10_Bust.mat\n",
      "Original reward 21.1887655116595\n",
      "13\n",
      "Final reward {26.80607734050481}\n",
      "8_10_Heart.mat\n",
      "Original reward 25.108909909526762\n",
      "12\n",
      "Final reward {28.771069406325246}\n"
     ]
    }
   ],
   "source": [
    "vanilla_eval_dataset = EvaluationDataset(block_size = \n",
    "                                         train_config.block_size//3, \n",
    "                                         rtg_scale = 1, \n",
    "                                         data_dir='evaluation/image_dir/metalearning/8_10/', \n",
    "                                         action_dim= 3, \n",
    "                                         rtg_target = rtg_target)\n",
    "eval_loader = DataLoader(dataset = vanilla_eval_dataset, batch_size=1) \n",
    "\n",
    "trainer = Trainer(model = model, train_config=train_config, action_dim=3, max_timesteps=30, context_length=6, train_data_loader=None, optimizer=optimizer, \n",
    "                  save_every=1, env = env, eval_loader= eval_loader, gpu_id= None, ddp = False, compile=False)\n",
    "\n",
    "trainer.run_evaluation(rtg_scale=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
